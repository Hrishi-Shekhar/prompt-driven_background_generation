
# ğŸ§  Prompt-Driven Background Generation for Image Augmentation

This repository contains a modular, production-ready pipeline that automates **background generation** for images using a combination of:

- Foreground removal (rembg)  
- Background inpainting (OpenCV)  
- Image captioning (Microsoft GIT)  
- Prompt refinement (GPT4All with Mistral)  
- Background generation (Stable Diffusion)

---

## ğŸš€ Pipeline Overview

This pipeline allows you to take an input image and generate a **new, realistic background** aligned with the scene's context, making it ideal for **image augmentation**, especially in medical or domain-sensitive applications.

### ğŸ”§ What the pipeline does:

1. **Foreground Removal**  
   Uses `rembg` to cleanly extract the object from the image.

2. **Inpainting**  
   Uses OpenCV's inpainting to restore the background after object removal.

3. **Caption Generation**  
   Applies Microsoftâ€™s `git-large-coco` model to describe the clean background.

4. **Prompt Refinement**  
   Uses a **local GPT4All model** (e.g., `mistral-7b-instruct`) to enhance the generated caption.

5. **Background Generation**  
   Uses Stable Diffusion (`runwayml/stable-diffusion-v1-5`) to generate a high-quality background from the refined prompt.

---

## ğŸ—‚ï¸ Folder Structure

```
prompt-driven-background-generation/
â”œâ”€â”€ bg_prompt_generation.py                                # Main pipeline script
â”œâ”€â”€ pipeline.log                             # Auto-generated logs
â”œâ”€â”€ Ancylostoma-Spp--68-_jpg...jpg           # Sample input image
â”œâ”€â”€ bg_only.png                              # Clean background (after inpainting)
â”œâ”€â”€ generated_image.png                      # Final generated background image
```

---

## ğŸ“¥ Requirements

Install the dependencies:

```bash
pip install torch torchvision transformers rembg diffusers accelerate opencv-python pillow gpt4all
```

> âš ï¸ Make sure you are using a supported version of Python (>=3.8).

---

## ğŸ“ Model Downloads

Download the following model manually before running the pipeline:

- ğŸ”¹ **GPT4All (Mistral GGUF)**  
  Download from: https://gpt4all.io/models/gguf/mistral-7b-instruct-v0.1.Q4_0.gguf  
  Place it inside a local `models/` directory or update the `model_path` in the script accordingly.

- ğŸ”¹ **Stable Diffusion**  
  Automatically downloaded via `diffusers` from Hugging Face (`runwayml/stable-diffusion-v1-5`) on first use.

- ğŸ”¹ **Microsoft GIT Model**  
  Also downloaded automatically: `microsoft/git-large-coco`

---

## â–¶ï¸ How to Run

1. Place your **input image** (e.g., a medical or object image) in the project directory.

2. Update these variables in `bg_prompt_generation.py`:

```python
input_path = "your_input_image.jpg"
model_name = "mistral-7b-instruct-v0.1.Q4_0.gguf"
model_path = "models/"
```

3. Run the script:

```bash
python bg_prompt_generation.py
```

4. The pipeline will output:

- `bg_only.png` â€“ inpainted clean background  
- `generated_image.png` â€“ AI-generated semantic background

---

## ğŸ› ï¸ Customization

- To use your own GPT4All model, just change `model_name` and `model_path`.
- You can replace the image with any relevant domain image.
- Supports CPU and CUDA (automatically detected).

---

## ğŸ§ª Example Use Case

With `Ancylostoma-Spp--68-...jpg`, the pipeline might:

1. Extract the worm foreground.
2. Inpaint the lab background.
3. Generate a caption: _â€œa clinical laboratory background with a sterile tableâ€_.
4. Refine to: _â€œa high-resolution clinical background suitable for microscopic worm imagingâ€_.
5. Generate a synthetic, context-aware background image.

---

## ğŸ“Œ Notes

- Internet is required to fetch Hugging Face models unless cached locally.
- Ensure your system meets the VRAM requirements for Stable Diffusion (8GB+ recommended).
- Logs are written to `pipeline.log` for debugging.

---


